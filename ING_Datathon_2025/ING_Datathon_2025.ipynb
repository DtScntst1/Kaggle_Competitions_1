{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd3e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.54459\n",
      "[100]\tvalidation_0-logloss:0.05417\n",
      "[200]\tvalidation_0-logloss:0.00863\n",
      "[300]\tvalidation_0-logloss:0.00262\n",
      "[400]\tvalidation_0-logloss:0.00179\n",
      "[500]\tvalidation_0-logloss:0.00169\n",
      "[600]\tvalidation_0-logloss:0.00167\n",
      "[700]\tvalidation_0-logloss:0.00167\n",
      "[799]\tvalidation_0-logloss:0.00169\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.00890564\n",
      "[400]\tvalid_0's binary_logloss: 0.00235914\n",
      "Early stopping, best iteration is:\n",
      "[399]\tvalid_0's binary_logloss: 0.00235382\n",
      "✅ Final rank-boosted submission kaydedildi: submission_rankboost.csv\n",
      "   cust_id     churn\n",
      "0        1  0.000062\n",
      "1        2  0.000055\n",
      "2        9  0.000057\n",
      "3       15  0.000056\n",
      "4       19  0.000053\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "rankboost_churn_pipeline.py\n",
    "\n",
    "Açıklama:\n",
    "Bu dosya, müşteri işlem geçmişi verisini kullanarak basit bir churn tahmin hattı (pipeline) oluşturmaktadır.\n",
    "\n",
    "Girdi dosyaları (örnek):\n",
    "- customer_history.csv      : Günlük/aylık müşteri işlem geçmişi (\"date\" ve \"cust_id\" içerir)\n",
    "- referance_data_test.csv   : Test seti (\"ref_date\" içerir)\n",
    "- sample_submission.csv     : Çıktı şablonu (\"cust_id\" ve muhtemelen beklenen hedef sütunu içerir)\n",
    "\n",
    "Çıktı:\n",
    "- submission.csv  : Hazırlanan tahminleri içeren csv\n",
    "\n",
    "Notlar / Gereksinimler:\n",
    "- scikit-learn, pandas, numpy, xgboost, lightgbm kütüphaneleri yüklü olmalıdır.\n",
    "- Bu pipeline eğitim verisinden proxy churn label (aktiflik tabanlı) oluşturur; gerçek etiketler yoksa bu yaklaşım kullanılabilir.\n",
    "- Hyperparametreler örnektir; gerçek kullanımda cross-validation veya zaman serisi validasyonu ile ayarlanmalıdır.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 1) Kütüphaneler\n",
    "# Veri işleme için pandas & numpy, ölçekleme ve veri bölme için sklearn,\n",
    "# modeller için XGBoost ve LightGBM.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2) Dosya yolları\n",
    "train_path = \"customer_history.csv\"\n",
    "test_path = \"referance_data_test.csv\"\n",
    "sample_path = \"sample_submission.csv\"\n",
    "out_path = \"submission_rankboost.csv\"\n",
    "\n",
    "# 3) Veri yükleme\n",
    "# Tarih sütunlarını parse_dates ile yükleyerek zaman aritmetiğini kolaylaştırılır.\n",
    "# \"date\" ve \"ref_date\" isimleri datasetinizde farklıysa burada uyarlanmalıdır.\n",
    "train = pd.read_csv(train_path, parse_dates=[\"date\"])  # eğitim (işlem geçmişi)\n",
    "test = pd.read_csv(test_path, parse_dates=[\"ref_date\"])  # referans/test tarihleri\n",
    "sample = pd.read_csv(sample_path)  # submission şablonu (cust_id listesi vb.)\n",
    "\n",
    "\n",
    "# 4) Otomatik sütun seçimi: transaction count / amount sütunları\n",
    "# Train setinde isimlendirme standartı varsa (_cnt, _amt gibi) bu kısım otomatik\n",
    "# sütunları algılar. Eğer farklıysa burada manuel tanımlayın.\n",
    "txn_cnt_cols = [c for c in train.columns if c.endswith(\"_cnt\")]\n",
    "txn_amt_cols = [c for c in train.columns if c.endswith(\"_amt\")]\n",
    "\n",
    "# ref_date: test dosyasındaki en son referans tarihini alınır. Bu tarih \"snapshot\" tarihi\n",
    "# olarak kullanılacak ve tüm pencere hesaplamaları bu tarihe göre yapılacaktır.\n",
    "ref_date = test[\"ref_date\"].max()\n",
    "\n",
    "# 5) Özellik oluşturucu fonksiyon (feature engineering)\n",
    "# make_features: verilen bir aylık pencere (months) için her müşteri bazında\n",
    "# toplu istatistikler üretir (sum, mean, std, max, min). Ayrıca aktif ürün sayısı\n",
    "# gibi kategorik/unique bilgi de çıkarılır.\n",
    "# Bu fonksiyonun davranışı dataset yapısına göre uyarlanabilir (ek istatistikler,\n",
    "# daha sofistike zaman serisi özellikleri vs.).\n",
    "def make_features(df, ref_date, months):\n",
    "    # Başlangıç zamanı: ref_date - months\n",
    "    start = ref_date - pd.DateOffset(months=months)\n",
    "\n",
    "    # Pencere içindeki kayıtları seç\n",
    "    sub = df[(df[\"date\"] > start) & (df[\"date\"] <= ref_date)].copy()\n",
    "\n",
    "    # Aggregasyon sözlüğü: her sayısal işlem sütunu için birden fazla istatistik\n",
    "    agg = sub.groupby(\"cust_id\").agg({\n",
    "        **{c: [\"sum\", \"mean\", \"std\", \"max\", \"min\"] for c in txn_cnt_cols + txn_amt_cols},\n",
    "        # aktif ürün kategorisi adedi: eşsiz sayısı ve maksimumu (örnek amaçlı)\n",
    "        \"active_product_category_nbr\": [\"nunique\", \"max\"]\n",
    "    })\n",
    "\n",
    "    # Çok seviyeli sütun isimlerini okunabilir tek seviyeye indirgeme\n",
    "    agg.columns = [f\"{a}_{b}_{months}m\" for a,b in agg.columns]\n",
    "    return agg.reset_index()\n",
    "\n",
    "# 6) Çoklu pencere (multi-window) özetleri\n",
    "# Farklı zaman pencereleri (3, 6, 12 ay) için özellikler hesaplanır. Bu, kısa ve uzun\n",
    "# dönem davranışlarını yakalamaya yardımcı olur.\n",
    "agg3 = make_features(train, ref_date, 3)\n",
    "agg6 = make_features(train, ref_date, 6)\n",
    "agg12 = make_features(train, ref_date, 12)\n",
    "\n",
    "# Merge: Tüm özellik setlerini cust_id üzerinden birleştiriyoruz. Eksik değerler 0 ile doldurulur.\n",
    "features = agg12.merge(agg6, on=\"cust_id\", how=\"outer\").merge(agg3, on=\"cust_id\", how=\"outer\").fillna(0)\n",
    "\n",
    "# 7) Trend & delta (oransal özellikler)\n",
    "# Örnek: 6 aylık toplam / 12 aylık toplam => son yarı dönemde hareket var mı?\n",
    "# 3 aylık / 6 aylık => kısa dönem değişim.\n",
    "for c in txn_cnt_cols + txn_amt_cols:\n",
    "    # 6m / 12m trend\n",
    "    if f\"{c}_sum_6m\" in features.columns and f\"{c}_sum_12m\" in features.columns:\n",
    "        # +1 ile bölme, sıfıra bölünmeyi ve logik oranları stabilize eder\n",
    "        features[f\"{c}_trend\"] = (features[f\"{c}_sum_6m\"] + 1) / (features[f\"{c}_sum_12m\"] + 1)\n",
    "    # 3m / 6m delta\n",
    "    if f\"{c}_sum_3m\" in features.columns and f\"{c}_sum_6m\" in features.columns:\n",
    "        features[f\"{c}_delta\"] = (features[f\"{c}_sum_3m\"] + 1) / (features[f\"{c}_sum_6m\"] + 1)\n",
    "\n",
    "# 8) Aktivite skoru ve proxy churn label oluşturma\n",
    "# Gerçek churn etiketleri yoksa, proxy olarak \"aktiflik\" bazlı bir kural tanımlanabilir.\n",
    "# Burada tüm \"sum_\" ile biten özellikleri topluyor, yüzde sıralama (rank pct) yapıyor ve\n",
    "# en düşük %25'i churn (1) olarak işaretliyoruz. Bu, basit ama etkili bir zayıf süpervizyon yöntemidir.\n",
    "activity_cols = [c for c in features.columns if \"sum_\" in c]\n",
    "features[\"activity_sum\"] = features[activity_cols].sum(axis=1)\n",
    "features[\"activity_rank\"] = features[\"activity_sum\"].rank(pct=True)\n",
    "\n",
    "# churn_label: düşük aktivite -> churn. 0 = aktif, 1 = churn (hedef değişimi gerektirebilir)\n",
    "features[\"churn_label\"] = (features[\"activity_rank\"] < 0.25).astype(int)  # en düşük %25 churn\n",
    "\n",
    "# 9) Ölçekleme (scaling) ve X/y ayrımı\n",
    "# RobustScaler: aykırı değerlere (outliers) karşı daha dayanıklı olduğu için tercih edildi.\n",
    "X = features.drop(columns=[\"cust_id\",\"churn_label\"])  # model girdileri\n",
    "y = features[\"churn_label\"]  # hedef\n",
    "scaler = RobustScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# 10) Train/validation split\n",
    "# Basit bir rastgele bölme. Zaman serisi problemlerinde zaman tabanlı validasyon veya\n",
    "# cross-validation kullanmak genelde daha doğrudur. Burada örnek amaçlı rastgele split kullanıldı.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 11) XGBoost ile eğitim\n",
    "# Parametreler örnektir. Daha iyi sonuç için hyperparametre optimizasyonu önerilir.\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.02,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "# eval_set ile validation üzerinde izlenebilir; verbose ile dönemlik çıktı alınır.\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=100)\n",
    "\n",
    "# 12) LightGBM ile eğitim\n",
    "# LightGBM için Dataset objeleri hazırlanır. callbacks kullanarak early stopping ve loglama eklenir.\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_val = lgb.Dataset(X_val, label=y_val)\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"num_leaves\": 96,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"min_data_in_leaf\": 30,\n",
    "    \"seed\": 42,\n",
    "    \"verbosity\": -1\n",
    "}\n",
    "\n",
    "# early_stopping: validation'da 100 round boyunca düzelme olmazsa durdur.\n",
    "callbacks = [lgb.early_stopping(stopping_rounds=100), lgb.log_evaluation(period=200)]\n",
    "# num_boost_round yüksek verildi; early stopping ile gerçek uygun iterasyon seçilecek.\n",
    "lgb_model = lgb.train(params, lgb_train, valid_sets=[lgb_val], num_boost_round=1500, callbacks=callbacks)\n",
    "\n",
    "# 13) Test için özellik seti oluşturma\n",
    "# submission için testteki cust_id'lerle eşleşen features satırları alınır. Eğer test setinde\n",
    "# ekstra müşteriler varsa veya zaman pencerelemesi farklıysa burada ek adımlar gerekir.\n",
    "test_feats = features[features[\"cust_id\"].isin(sample[\"cust_id\"])].copy()\n",
    "X_test = pd.DataFrame(scaler.transform(test_feats.drop(columns=[\"cust_id\",\"churn_label\"])), columns=X.columns)\n",
    "\n",
    "# 14) Model tahminleri\n",
    "# XGBoost predict_proba ile olasılık alınır; LightGBM için predict kullanılır.\n",
    "p_xgb = xgb_model.predict_proba(X_test)[:,1]\n",
    "p_lgb = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "# 15) Ağırlıklı blend (ensemble)\n",
    "# İki modelin ağırlıklı ortalaması alınır. Ağırlıklar ihtiyaca göre değiştirilebilir.\n",
    "blend = 0.6*p_lgb + 0.4*p_xgb\n",
    "\n",
    "# 16) Rank-based calibration (top boosting)\n",
    "# Bu adım rank tabanlı küçük bir hack: üst %10 ve %5'lik dilimlere ekstra multiplier uygulayarak\n",
    "# \"rank boost\" yapıyoruz. Bu tip ayarlamalar leaderboard odaklı yarışmalarda yaygındır fakat\n",
    "# gerçek iş uygulamalarında dikkatli kullanılmalıdır (overfitting riski).\n",
    "rank = pd.Series(blend).rank(pct=True)\n",
    "boosted = blend.copy()\n",
    "# Üst %10'u %50 arttır (1.5), üst %5'i daha da arttırarak (1.8)\n",
    "boosted[rank > 0.9] *= 1.5\n",
    "boosted[rank > 0.95] *= 1.8\n",
    "boosted = np.clip(boosted, 0, 1)  # olasılıkları [0,1] aralığına zorla\n",
    "\n",
    "# 17) Submission oluşturma ve kaydetme\n",
    "sub = sample.copy()\n",
    "\n",
    "# sample dosyasında hedef sütun adı farklıysa (ör. \"target\" veya \"churn\") burada uyarlayın.\n",
    "sub[\"churn\"] = boosted\n",
    "sub.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"\\u2705 Final rank-boosted submission kaydedildi: {out_path}\")\n",
    "print(sub.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
